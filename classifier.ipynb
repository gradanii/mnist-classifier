{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "def get_mean_std(loader):\n",
    "    # Compute the mean and standard deviation of all pixels in the dataset\n",
    "    num_pixels = 0\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    for images, _ in loader:\n",
    "        batch_size, num_channels, height, width = images.shape\n",
    "        num_pixels += batch_size * height * width\n",
    "        mean += images.mean(axis=(0, 2, 3)).sum()\n",
    "        std += images.std(axis=(0, 2, 3)).sum()\n",
    "\n",
    "    mean /= num_pixels\n",
    "    std /= num_pixels\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "mean, std = get_mean_std(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1308,), (0.3081,))\n",
    "])\n",
    "\n",
    "training = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=data_transforms,\n",
    ")\n",
    "\n",
    "testing = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=data_transforms,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))  # Get one batch\n",
    "print(images.shape, labels.shape)  # Expected: (batch_size, 1, 28, 28), (batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------------------\n",
      "loss: 2.303183  [   64/60000]\n",
      "loss: 2.292202  [ 6464/60000]\n",
      "loss: 2.301175  [12864/60000]\n",
      "loss: 2.292846  [19264/60000]\n",
      "loss: 2.287432  [25664/60000]\n",
      "loss: 2.287675  [32064/60000]\n",
      "loss: 2.285464  [38464/60000]\n",
      "loss: 2.263934  [44864/60000]\n",
      "loss: 2.275370  [51264/60000]\n",
      "loss: 2.258931  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 39.2%, Avg loss: 2.261051 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------------------\n",
      "loss: 2.256676  [   64/60000]\n",
      "loss: 2.259790  [ 6464/60000]\n",
      "loss: 2.250911  [12864/60000]\n",
      "loss: 2.254636  [19264/60000]\n",
      "loss: 2.232683  [25664/60000]\n",
      "loss: 2.228674  [32064/60000]\n",
      "loss: 2.239135  [38464/60000]\n",
      "loss: 2.213770  [44864/60000]\n",
      "loss: 2.193835  [51264/60000]\n",
      "loss: 2.191413  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 2.197659 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------------------\n",
      "loss: 2.186944  [   64/60000]\n",
      "loss: 2.183985  [ 6464/60000]\n",
      "loss: 2.172227  [12864/60000]\n",
      "loss: 2.169058  [19264/60000]\n",
      "loss: 2.175971  [25664/60000]\n",
      "loss: 2.154008  [32064/60000]\n",
      "loss: 2.173975  [38464/60000]\n",
      "loss: 2.149212  [44864/60000]\n",
      "loss: 2.117660  [51264/60000]\n",
      "loss: 2.076122  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 2.089994 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------------------\n",
      "loss: 2.080667  [   64/60000]\n",
      "loss: 2.088238  [ 6464/60000]\n",
      "loss: 2.086322  [12864/60000]\n",
      "loss: 2.029750  [19264/60000]\n",
      "loss: 2.046253  [25664/60000]\n",
      "loss: 1.974096  [32064/60000]\n",
      "loss: 1.969084  [38464/60000]\n",
      "loss: 1.945244  [44864/60000]\n",
      "loss: 1.972136  [51264/60000]\n",
      "loss: 1.951564  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 1.900885 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------------------\n",
      "loss: 1.904216  [   64/60000]\n",
      "loss: 1.877887  [ 6464/60000]\n",
      "loss: 1.807301  [12864/60000]\n",
      "loss: 1.848511  [19264/60000]\n",
      "loss: 1.850306  [25664/60000]\n",
      "loss: 1.734309  [32064/60000]\n",
      "loss: 1.642716  [38464/60000]\n",
      "loss: 1.696900  [44864/60000]\n",
      "loss: 1.713146  [51264/60000]\n",
      "loss: 1.690591  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 1.611275 \n",
      "\n",
      "Epoch 6\n",
      "--------------------------------------\n",
      "loss: 1.700938  [   64/60000]\n",
      "loss: 1.583135  [ 6464/60000]\n",
      "loss: 1.437699  [12864/60000]\n",
      "loss: 1.501026  [19264/60000]\n",
      "loss: 1.521559  [25664/60000]\n",
      "loss: 1.359919  [32064/60000]\n",
      "loss: 1.507721  [38464/60000]\n",
      "loss: 1.350091  [44864/60000]\n",
      "loss: 1.315264  [51264/60000]\n",
      "loss: 1.450451  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 1.285012 \n",
      "\n",
      "Epoch 7\n",
      "--------------------------------------\n",
      "loss: 1.282699  [   64/60000]\n",
      "loss: 1.153747  [ 6464/60000]\n",
      "loss: 1.326582  [12864/60000]\n",
      "loss: 1.171305  [19264/60000]\n",
      "loss: 1.209149  [25664/60000]\n",
      "loss: 1.103329  [32064/60000]\n",
      "loss: 1.153516  [38464/60000]\n",
      "loss: 1.236973  [44864/60000]\n",
      "loss: 1.035284  [51264/60000]\n",
      "loss: 1.101486  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 1.023944 \n",
      "\n",
      "Epoch 8\n",
      "--------------------------------------\n",
      "loss: 1.203340  [   64/60000]\n",
      "loss: 1.084945  [ 6464/60000]\n",
      "loss: 1.109807  [12864/60000]\n",
      "loss: 0.944022  [19264/60000]\n",
      "loss: 1.036231  [25664/60000]\n",
      "loss: 0.967165  [32064/60000]\n",
      "loss: 0.797941  [38464/60000]\n",
      "loss: 0.876096  [44864/60000]\n",
      "loss: 0.979917  [51264/60000]\n",
      "loss: 0.842858  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.848670 \n",
      "\n",
      "Epoch 9\n",
      "--------------------------------------\n",
      "loss: 0.808877  [   64/60000]\n",
      "loss: 0.875015  [ 6464/60000]\n",
      "loss: 0.835033  [12864/60000]\n",
      "loss: 0.957086  [19264/60000]\n",
      "loss: 0.863864  [25664/60000]\n",
      "loss: 0.768549  [32064/60000]\n",
      "loss: 0.762580  [38464/60000]\n",
      "loss: 0.814699  [44864/60000]\n",
      "loss: 0.939493  [51264/60000]\n",
      "loss: 0.734237  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.730254 \n",
      "\n",
      "Epoch 10\n",
      "--------------------------------------\n",
      "loss: 0.606248  [   64/60000]\n",
      "loss: 0.605646  [ 6464/60000]\n",
      "loss: 0.672336  [12864/60000]\n",
      "loss: 0.744200  [19264/60000]\n",
      "loss: 0.672410  [25664/60000]\n",
      "loss: 0.725718  [32064/60000]\n",
      "loss: 0.591808  [38464/60000]\n",
      "loss: 0.690462  [44864/60000]\n",
      "loss: 0.508899  [51264/60000]\n",
      "loss: 0.554956  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.647212 \n",
      "\n",
      "Epoch 11\n",
      "--------------------------------------\n",
      "loss: 0.580364  [   64/60000]\n",
      "loss: 0.805538  [ 6464/60000]\n",
      "loss: 0.629096  [12864/60000]\n",
      "loss: 0.707673  [19264/60000]\n",
      "loss: 0.513877  [25664/60000]\n",
      "loss: 0.411020  [32064/60000]\n",
      "loss: 0.734049  [38464/60000]\n",
      "loss: 0.612648  [44864/60000]\n",
      "loss: 0.603685  [51264/60000]\n",
      "loss: 0.603993  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.585653 \n",
      "\n",
      "Epoch 12\n",
      "--------------------------------------\n",
      "loss: 0.732735  [   64/60000]\n",
      "loss: 0.529946  [ 6464/60000]\n",
      "loss: 0.644659  [12864/60000]\n",
      "loss: 0.660385  [19264/60000]\n",
      "loss: 0.492854  [25664/60000]\n",
      "loss: 0.656795  [32064/60000]\n",
      "loss: 0.514606  [38464/60000]\n",
      "loss: 0.485507  [44864/60000]\n",
      "loss: 0.663285  [51264/60000]\n",
      "loss: 0.493525  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.541168 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 12\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n--------------------------------------')\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    test_loop(test_loader, model, loss_fn)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(X.shape)  # Should be [batch_size, 1, 28, 28]\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'mnist.pth')\n",
    "print('Model saved successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_image, test_label = testing[2] \n",
    "test_image = test_image.unsqueeze(2) \n",
    "\n",
    "test_image = test_image.to(device)\n",
    "model.to(device)\n",
    "\n",
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    output = model(test_image)\n",
    "\n",
    "predicted_label = output.argmax(1).item()\n",
    "\n",
    "plt.imshow(test_image.cpu().squeeze(), cmap=\"gray\")\n",
    "plt.title(f\"Predicted: {predicted_label}, Actual: {test_label}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
